{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 1: Data Analysis of Singapore Rainfall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# Part 1\n",
    "\n",
    "Part 1 requires knowledge of basic Python.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents:\n",
    "- [Background](#Background)\n",
    "- [Data Import & Cleaning](#Data-Import-and-Cleaning)\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "- [Data Visualization](#Visualize-the-Data)\n",
    "- [Conclusions and Recommendations](#Conclusions-and-Recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the [Meteorological Services Singapore](http://www.weather.gov.sg/climate-climate-of-singapore/#:~:text=Singapore%20is%20situated%20near%20the,month%2Dto%2Dmonth%20variation.), Singapore has typical tropical climate with abundant rainfall, high and uniform temperatures and high humidity all year round, since its situated near the equator. There are many factors that help us understand the climate of a country and in this project we are going to look into a few, especially rainfall.\n",
    "\n",
    "Singapore’s climate is characterised by two main monsoon seasons separated by inter-monsoonal periods.  The **Northeast Monsoon** occurs from December to early March, and the **Southwest Monsoon** from June to September.\n",
    "\n",
    "The major weather systems affecting Singapore that can lead to heavy rainfall are:\n",
    "\n",
    "-Monsoon surges, or strong wind episodes in the Northeast Monsoon flow bringing about major rainfall events;\n",
    "\n",
    "-Sumatra squalls, an organised line of thunderstorms travelling eastward across Singapore, having developed over the island of Sumatra or Straits of Malacca west of us;\n",
    "\n",
    "-Afternoon and evening thunderstorms caused by strong surface heating and by the sea breeze circulation that develops in the afternoon.\n",
    "\n",
    "Singapore’s climate station has been located at several different sites in the past 140 years. The station had been decommissioned at various points in the past due to changes to local land use in the site’s vicinity, and had to be relocated. Since 1984, the climate station has been located at **Changi**.\n",
    "\n",
    "There are other metrics of climate such as temperature, humidity, sun shine duration, wind speed, cloud cover etc. All the dataset used in the project comes from [data.gov.sg](data.gov.sg), as recorded at the Changi climate station \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose your Data\n",
    "\n",
    "There are 2 datasets included in the [`data`](./data/) folder for this project. These correponds to rainfall information. \n",
    "\n",
    "* [`rainfall-monthly-number-of-rain-days.csv`](./data/rainfall-monthly-number-of-rain-days.csv): Monthly number of rain days from 1982 to 2022. A day is considered to have “rained” if the total rainfall for that day is 0.2mm or more.\n",
    "* [`rainfall-monthly-total.csv`](./data/rainfall-monthly-total.csv): Monthly total rain recorded in mm(millimeters) from 1982 to 2022\n",
    "\n",
    "Other relevant weather datasets from [data.gov.sg](data.gov.sg) that you can download and use are as follows:\n",
    "\n",
    "* [Relative Humidity](https://data.gov.sg/dataset/relative-humidity-monthly-mean)\n",
    "* [Monthly Maximum Daily Rainfall](https://data.gov.sg/dataset/rainfall-monthly-maximum-daily-total)\n",
    "* [Hourly wet buld temperature](https://data.gov.sg/dataset/wet-bulb-temperature-hourly)\n",
    "* [Monthly mean sunshine hours](https://data.gov.sg/dataset/sunshine-duration-monthly-mean-daily-duration)\n",
    "* [Surface Air Temperature](https://data.gov.sg/dataset/surface-air-temperature-mean-daily-minimum)\n",
    "\n",
    "You can also use other datasets for your analysis, make sure to cite the source when you are using them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To-Do:**\n",
    "### Data sources\n",
    "\n",
    "#### <a href= \"Data sources/raindays_by_mth.csv\"> Number of Rainy Days per Month (Jan 2010 - Dec 2019) </a>\n",
    "\n",
    "* 121 rows, 2 columns\n",
    "* Illustrates the no. of rainy days per month from Jan 2010 to Dec 2019\n",
    "\n",
    "#### <a href= \"Data sources/road_acc_by_mth.csv\"> Number of Casualties: Fatalities and Injuries (Jan 2010 - Dec 2019) </a>\n",
    "\n",
    "* 120 rows, 29 columns\n",
    "* Illustrates the no. of road accident casualties fatalities and injured, as well as a breakdown of those by vehicle type <br><br>\n",
    "\n",
    "**Note:**\n",
    "* The research analysis spanned a ten-year period from January 2010 to December 2019.\n",
    "* Data sets were aggregated on a monthly basis over this ten-year period to neutralize the effect of irregular weather phenomena, such as the El Niño event in 2015-2016,  and instances of intense rainfall/flooding in Jun 2010, Jan 2011, and Jan 2018.\n",
    "* Data from 2020 onwards were excluded due to the effects of the COVID-19 pandemic.\n",
    "* Data related to Personal Mobile Devices (PMD) were excluded since PMDs came into existence in Singapore only from 2017 onwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To-Do:**<br>\n",
    "Rainy days can impede our navigation skills due to more slippery surfaces and compromised vision, resulting in casualties.\n",
    "\n",
    "To what extent does weather play a part in road safety? \n",
    "How can we minimize road accidents stemmed from rainy weather?<br><br>\n",
    "\n",
    "This project aims to find out:\n",
    "1. The effect of **rainy days** on the **number of road accident casualties** (correlation between number of rainy days vs casualties per month)\n",
    "2. Whether rainy weather **aggravates** road accidents (correlation between number of rainy days vs fatalities, number of rainy days vs injured per month)\n",
    "3. The **vehicle types** that are more prone to road accidents (rank number of casualties by vehicle types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outside Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your problem statement and your chosen datasets, spend some time doing outside research on how climate change is affecting different industries or additional information that might be relevant. Summarize your findings below. If you bring in any outside tables or charts, make sure you are explicit about having borrowed them. If you quote any text, make sure that it renders as being quoted. **Make sure that you cite your sources.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To-Do:**\n",
    "\n",
    "Data souce for road accident casualties:\n",
    "- https://tablebuilder.singstat.gov.sg/\n",
    "\n",
    "Other research:\n",
    "- https://www.budgetdirect.com.sg/car-insurance/research/road-accident-statistics-in-singapore\n",
    "- https://www.directasia.com/blog/reduce-risk-road-accidents-singapore\n",
    "- https://www.motorist.sg/article/173/the-5-most-common-causes-for-road-accidents-in-singapore\n",
    "- https://msgt.com.sg/accident-hotspots-in-singapore-to-watch-out-for/\n",
    "- http://www.smj.org.sg/article/geospatial-analysis-severe-road-traffic-accidents-singapore-2013%E2%80%932014\n",
    "- https://www.valuechampion.sg/probability-car-accident\n",
    "- https://www.weather.gov.sg/wp-content/uploads/2020/03/Annual-Climate-Assessment-Report-2019.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding Challenges\n",
    "\n",
    "1. Manually calculate mean:\n",
    "\n",
    "    Write a function that takes in values and returns the mean of the values. Create a list of numbers that you test on your function to check to make sure your function works!\n",
    "    \n",
    "    *Note*: Do not use any mean methods built-in to any Python libraries to do this! This should be done without importing any additional libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(num_list):\n",
    "    mean = sum(num_list)/len(num_list)\n",
    "    return mean\n",
    "\n",
    "num_list = [2, 4, 8, 5, 1]\n",
    "print(mean(num_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Manually calculate standard deviation:\n",
    "\n",
    "    The formula for standard deviation is below:\n",
    "\n",
    "    $$\\sigma = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu)^2}$$\n",
    "\n",
    "    Where $x_i$ represents each value in the dataset, $\\mu$ represents the mean of all values in the dataset and $n$ represents the number of values in the dataset.\n",
    "\n",
    "    Write a function that takes in values and returns the standard deviation of the values using the formula above. Hint: use the function you wrote above to calculate the mean! Use the list of numbers you created above to test on your function.\n",
    "    \n",
    "    *Note*: Do not use any standard deviation methods built-in to any Python libraries to do this! This should be done without importing any additional libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_dev(num_list):\n",
    "    \n",
    "    i = 0\n",
    "    diff_sq = []\n",
    "    while i < len(num_list):\n",
    "        diff_sq.append((num_list[i] - mean(num_list)) ** 2)\n",
    "        i += 1\n",
    "        \n",
    "    std_dev = (sum(diff_sq)/len(num_list)) ** 0.5\n",
    "    return std_dev\n",
    "\n",
    "num_list = [2, 4, 8, 5, 1]\n",
    "print(std_dev(num_list))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# Part 2\n",
    "\n",
    "Part 2 requires knowledge of Pandas, EDA, data cleaning, and data visualization.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*All libraries used should be added here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import & Cleaning\n",
    "\n",
    "Import all the datasets that you selected for this project and go through the following steps at a minimum. You are welcome to do further cleaning as you feel necessary. Make sure to comment your code to showcase the intent behind the data processing step.\n",
    "1. Display the data: print the first 5 rows of each dataframe to your Jupyter notebook.\n",
    "2. Check for missing values and datatype.\n",
    "3. Check for any obvious issues with the observations.\n",
    "4. Fix any errors you identified in steps 2-3.\n",
    "6. Fix any incorrect data types found in step 5.\n",
    "    - Fix any individual values preventing other columns from being the appropriate type.\n",
    "    - If the month column data is better analyzed as month and year, create new columns for the same\n",
    "7. Rename Columns.\n",
    "    - Column names should be all lowercase.\n",
    "    - Column names should not contain spaces (underscores will suffice--this allows for using the `df.column_name` method to access columns in addition to `df['column_name']`).\n",
    "    - Column names should be unique and informative.\n",
    "8. Drop unnecessary rows (if needed).\n",
    "9. Merge dataframes that can be merged.\n",
    "    - Since different climate metrics are in month format, you can merge them into one single dataframe for easier analysis\n",
    "10. Perform any additional cleaning that you feel is necessary.\n",
    "11. Save your cleaned and merged dataframes as csv files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary\n",
    "\n",
    "Now that we've fixed our data, and given it appropriate names, let's create a [data dictionary](http://library.ucmerced.edu/node/10249). \n",
    "\n",
    "A data dictionary provides a quick overview of features/variables/columns, alongside data types and descriptions. The more descriptive you can be, the more useful this document is.\n",
    "\n",
    "Example of a Fictional Data Dictionary Entry: \n",
    "\n",
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|**county_pop**|*integer*|2010 census|The population of the county (units in thousands, where 2.5 represents 2500 people).| \n",
    "|**per_poverty**|*float*|2010 census|The percent of the county over the age of 18 living below the 200% of official US poverty rate (units percent to two decimal places 98.10 means 98.1%)|\n",
    "\n",
    "[Here's a quick link to a short guide for formatting markdown in Jupyter notebooks](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html).\n",
    "\n",
    "Provided is the skeleton for formatting a markdown table, with columns headers that will help you create a data dictionary to quickly summarize your data, as well as some examples. **This would be a great thing to copy and paste into your custom README for this project.**\n",
    "\n",
    "*Note*: if you are unsure of what a feature is, check the source of the data! This can be found in the README."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Number of Rainy Days Data\n",
    "The \"raindays_by_mth.csv\" file presents the amount of rainfall per month from Jan 2010 to Dec 2019.\n",
    "\n",
    "Here are the steps to clean the following data:\n",
    "\n",
    "1. Import data into a dataframe named df_rain.   \n",
    "2. Check for missing values and datatypes.    \n",
    "3. Address obvious issues in step 2.\n",
    "4. Split \"month\" into \"year\" and \"month\".\n",
    "\n",
    "Note: The column names of df_rain are already in lowercase and snakecase with no spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Import data into a dataframe named df_rain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rain = pd.read_csv(\"Data sources/raindays_by_mth.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print first 5 rows\n",
    "df_rain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Check for missing values and datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df_rain.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "df_rain.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No null values found.  \n",
    "- But the \"month\" column is corrupted; the datatype should be datetime and not object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Address obvious issues in step b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data type of \"month\" to datetime\n",
    "df_rain[\"date\"] = pd.to_datetime(df_rain[\"month\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Split \"month\" into \"yr\" and \"mth\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of df_rain named df_rain_copy to prevent \"SettingWithCopyWarning\" error (modifying a DataFrame that might be a view on another DataFrame)\n",
    "df_rain_copy = df_rain.copy()\n",
    "\n",
    "# Split \"date\" into \"year\" and \"month\"\n",
    "df_rain_copy[\"yr\"] = df_rain_copy[\"date\"].dt.year\n",
    "df_rain_copy[\"mth\"] = df_rain_copy[\"date\"].dt.month\n",
    "\n",
    "# Change \"date\" into string in the format of YYYY-MM.\n",
    "df_rain_copy[\"date\"] = df_rain_copy[\"date\"].dt.strftime(\"%Y-%m\")\n",
    "\n",
    "# Rearrange columns where \"date\" comes before \"total_rainfall\"\n",
    "df_rain_cleaned = df_rain_copy[[\"date\", \"yr\", \"mth\", \"rain_days\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Add new column, log_raindays, log (base-10) of rain_days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rain_cleaned[\"log_raindays\"] = np.log10(df_rain_cleaned[\"rain_days\"])\n",
    "\n",
    "df_rain_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Road Accident Casualties Data\n",
    "The \"road_acc_by_mth.csv\" file presents the number of deaths and injured, as well as a breakdown of both categories by vehicle type, from Jan 2010 to Dec 2019.\n",
    "\n",
    "The \"Personal Mobility Devices\" category has been omitted as they have only come into existence from 2017 onwards.\n",
    "\n",
    "Here are the steps to clean the following data:\n",
    "\n",
    "* a. Import data into a dataframe named df_acc.\n",
    "* b. Transpose data.\n",
    "* c. Check for missing values and data types.\n",
    "* d. Address obvious issues in step c.\n",
    "* e. Split \"month\" into \"year\" and \"month\".\n",
    "* f. Rename columns.\n",
    "* g. Aggregate values of the same vehicle type into a column.\n",
    "* h. Add a new column, \"total_cas\", that sums up all values of deaths and injured.\n",
    "* i. Create a new df with the columns required. Rearrange the order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Import data into a dataframe named df_acc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc = pd.read_csv(\"Data Sources/road_acc_by_mth.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Transpose data.\n",
    "This step is crucial as the dates in df_acc are in the rows. We want to transpose them into columns to match that of df_rain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc = df_acc.set_index(\"Data Series\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print first 5 rows\n",
    "df_acc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Check for missing values and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values \n",
    "df_acc.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check data types\n",
    "df_acc.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No null values found.  \n",
    "- No corrupted data found as all values of casualties are integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Address obvious issues in step c.\n",
    "- The date format in df_acc (e.g. 2010 Jan) needs to be changed (e.g. 2010-01) to match that of df_rain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column headers\n",
    "df_acc.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It appears that all the column titles contain spacing at the end and this has to be removed before formatting the date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column at the end named \"Date\" that presents dates without trailling space. \n",
    "# Use .index.str.strip() to remove the trailling space.\n",
    "df_acc[\"Date\"] = df_acc.index.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change date format from \"2010 Jan\" to \"2010-01\".\n",
    "df_acc[\"Date\"] = pd.to_datetime(df_acc[\"Date\"], format=\"%Y %b\").dt.strftime(\"%Y-%m\")\n",
    "\n",
    "df_acc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Split \"month\" into \"yr\" and \"mth\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data type of \"Date\" column.\n",
    "df_acc.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The \"Date\" column is corrupted as the data type should be datetime and not object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change \"Date\" data type to datetime.\n",
    "df_acc[\"Date\"] = pd.to_datetime(df_acc[\"Date\"])\n",
    "df_acc[\"Date\"].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split \"Date\" into \"yr\" and \"mth\".\n",
    "df_acc[\"yr\"] = df_acc[\"Date\"].dt.year\n",
    "df_acc[\"mth\"] = df_acc[\"Date\"].dt.month\n",
    "\n",
    "#Change \"date\" into string in the format of YYYY-MM.\n",
    "df_acc[\"Date\"] = df_acc[\"Date\"].dt.strftime(\"%Y-%m\")\n",
    "\n",
    "df_acc[\"Date\"].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f. Rename columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print column header names to see how they should be reformatted\n",
    "df_acc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove leading and trailing spaces in column titles.\n",
    "#Lowercase all column titles and\n",
    "#Replace space between words with underscore.\n",
    "\n",
    "df_acc.columns = [col.strip().lower().replace(\" \", \"_\") for col in df_acc.columns]\n",
    "\n",
    "df_acc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shorten \"total_casualties_fatalities\" into \"total_deaths\".\n",
    "df_acc[\"total_deaths\"] = df_acc[\"total_casualties_fatalities\"]\n",
    "\n",
    "#Shorten \"total_casualties_injured\" into \"total_injured\".\n",
    "df_acc[\"total_injured\"] = df_acc[\"total_casualties_injured\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g. Aggregate values of the same vehicle type into a column by month.\n",
    "\n",
    "There are two repeated columns of the same vehicle type (one for total_casualties_fatalities and the other for total_casualties_death). This step removes columns of repeated header and combines them into a single column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicated columns by summing up values of the same header into a single column\n",
    "df_acc_grouped = df_acc.groupby(axis=1, level=0).sum()\n",
    "\n",
    "df_acc_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h. Add a new columns:\n",
    "- \"total_cas\": short for total number of casualties, that sums up all values of deaths and injured.\n",
    "- \"log_cas\": log (base-10) of total_cas\n",
    "- \"log_deaths\": log (base-10) of total_deaths\n",
    "- \"log_injured\": log (base-10) of total_injured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_grouped[\"total_cas\"] = df_acc_grouped[\"total_deaths\"] + df_acc_grouped[\"total_injured\"]\n",
    "df_acc_grouped[\"log_cas\"] = np.log10(df_acc_grouped[\"total_cas\"])\n",
    "df_acc_grouped[\"log_deaths\"] = np.log10(df_acc_grouped[\"total_deaths\"])\n",
    "df_acc_grouped[\"log_injured\"] = np.log10(df_acc_grouped[\"total_injured\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Create a new df with the columns required. Rearrange the order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_cleaned = df_acc_grouped[[\"date\", \"yr\", \"mth\", \"total_cas\", \"total_deaths\", \"total_injured\", \"log_cas\", \"log_deaths\", \"log_injured\", \"buses\", \"cyclists_&_pillions\", \"goods_vans\", \"lorries\", \"motor_cars_and_station_wagons\", \"motor_cyclists_&_pillion_riders\", \"pedestrians\", \"pick-ups\", \"tipper_trucks\", \"trailers\", \"others\"]].reset_index(drop=True)\n",
    "          \n",
    "df_acc_cleaned.head()            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create new dataframes for data analysis:\n",
    "**df_rain_acc**: merging data from both df_rain_cleaned and df_acc_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_rain_cleaned and df_acc_cleaned into a single df with their common columns: \"date\", \"yr\" and \"mth\".\n",
    "df_rain_acc = pd.merge(df_rain_cleaned, df_acc_cleaned, how=\"left\", on=[\"date\", \"yr\", \"mth\"])\n",
    "\n",
    "df_rain_acc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sum up data of the same month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the column header.\n",
    "df_rain_acc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by month and aggregate values.\n",
    "\n",
    "rain_acc_mthly = df_rain_acc.groupby(\"mth\").agg({\n",
    "    'rain_days': \"sum\", \n",
    "    'log_raindays': \"sum\", \n",
    "    'total_cas': \"sum\",\n",
    "    'total_deaths': \"sum\", \n",
    "    'total_injured': \"sum\", \n",
    "    'log_cas': \"sum\", \n",
    "    'log_deaths': \"sum\", \n",
    "    'log_injured': \"sum\",\n",
    "    'buses': \"sum\", \n",
    "    'cyclists_&_pillions': \"sum\", \n",
    "    'goods_vans': \"sum\", \n",
    "    'lorries': \"sum\",\n",
    "    'motor_cars_and_station_wagons': \"sum\", \n",
    "    'motor_cyclists_&_pillion_riders': \"sum\",\n",
    "    'pedestrians': \"sum\", \n",
    "    'pick-ups': \"sum\", \n",
    "    'tipper_trucks': \"sum\", \n",
    "    'trailers': \"sum\", \n",
    "    'others': \"sum\"\n",
    "}).reset_index()\n",
    "\n",
    "rain_acc_mthly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To-Do: Data dictionary**\n",
    "\n",
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|total_rainfall|float|rainfall-monthly-total|Total rainfall in mm|\n",
    "|date|object|raindays_by_mth & road_acc_by_mth|Date in YYYY-MM format|\n",
    "|yr|integer|raindays_by_mth & road_acc_by_mth|Year in YYYY format|\n",
    "|mth|integer|raindays_by_mth & road_acc_by_mth|Month in MM format|\n",
    "|rain_days|integer|raindays_by_mth|No. of rainy days in a month|\n",
    "|log_raindays|float|raindays_by_mth|Log (base-10) of rain_days|\n",
    "|total_deaths|integer|road_acc_by_mth|Total road accident casualties fatalities|\n",
    "|total_injured|integer|road_acc_by_mth|Total road accident casualties injured|\n",
    "|total_cas|integer|road_acc_by_mth|Sum of total_deaths and total_injured|\n",
    "|log_deaths|float|road_acc_by_mth|Log (base-10) of total_deaths|\n",
    "|log_injured|float|road_acc_by_mth|Log (base-10) of total_injured|\n",
    "|log_cas|float|road_acc_by_mth|Log (base-10) of total_cas|\n",
    "|buses, cyclists_&_ pillions, goods_vans, lorries, motor_cars_and_station_wagons, motor_cyclists_&_ pillion_riders, pedestrians, pick_ups, tipper_trucks, trailers, others|integer|road_acc_by_mth|Number of casualties of the respective vehicle type|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "Complete the following steps to explore your data. You are welcome to do more EDA than the steps outlined here as you feel necessary:\n",
    "1. Summary Statistics.\n",
    "2. Use a **dictionary comprehension** to apply the standard deviation function you create in part 1 to each numeric column in the dataframe.  **No loops**.\n",
    "    - Assign the output to variable `sd` as a dictionary where: \n",
    "        - Each column name is now a key \n",
    "        - That standard deviation of the column is the value \n",
    "        - *Example Output :* `{'rainfall-monthly-total': xxx, 'no_of_rainy_days': xxx, ...}`\n",
    "3. Investigate trends in the data.\n",
    "    - Using sorting and/or masking (along with the `.head()` method to avoid printing our entire dataframe), consider questions relevant to your problem statement. Some examples are provided below (but feel free to change these questions for your specific problem):\n",
    "        - Which month have the highest and lowest total rainfall in 1990, 2000, 2010 and 2020?\n",
    "        - Which year have the highest and lowest total rainfall in the date range of analysis?\n",
    "        - Which month have the highest and lowest number of rainy days in 1990, 2000, 2010 and 2020?\n",
    "        - Which year have the highest and lowest number of rainy days in the date range of analysis?\n",
    "        - Are there any outliers months in the dataset?\n",
    "       \n",
    "    - **The above 5 questions are compulsory. Feel free to explore other trends based on the datasets that you have choosen for analysis. You should comment on your findings at each step in a markdown cell below your code block**. Make sure you include at least one example of sorting your dataframe by a column, and one example of using boolean filtering (i.e., masking) to select a subset of the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_acc_mthly.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Apply the standard deviation function you create in part 1 to each numeric column in the dataframe.\n",
    "\n",
    "Assign the output to variable sd as a dictionary where:  \n",
    "- Each column name is now a key  \n",
    "- That standard deviation of the column is the value  \n",
    "- Example Output : {'rainfall-monthly-total': xxx, 'no_of_rainy_days': xxx, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new df consisting of just the log values\n",
    "log_rain_acc = [[\"date\", \"yr\", \"mth\", \"log_raindays\", \"log_cas\", \"log_deaths\", \"log_injured\"]].reset_index(drop=True)\n",
    "\n",
    "std_dev_rain_acc = log_rain_acc.apply(std_dev(log_rain_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Investigate trends in the data.\n",
    "- Using sorting and/or masking (along with the `.head()` method to avoid printing our entire dataframe), consider questions relevant to your problem statement. Some examples are provided below (but feel free to change these questions for your specific problem):\n",
    "     - Which month have the highest and lowest total rainfall in 1990, 2000, 2010 and 2020?\n",
    "     - Which year have the highest and lowest total rainfall in the date range of analysis?\n",
    "     - Which month have the highest and lowest number of rainy days in 1990, 2000, 2010 and 2020?\n",
    "     - Which year have the highest and lowest number of rainy days in the date range of analysis?\n",
    "     - Are there any outliers months in the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To-Do:** Please see the 5 questions relevant to my problem statement.\n",
    "\n",
    "1. What is the correlation between the number of rainy days and the number of casualties?\n",
    "2. What is the correlation between the number of rainy days and the number of deaths?\n",
    "3. What is the correlation between the number of rainy days and the number of injured?\n",
    "4. Which are the top three vehicle types with the highest number of casualties in total?\n",
    "5. Are there any outliers months in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Correlation between log_raindays and log_cas.\n",
    "rain_acc_mthly[[\"log_raindays\", \"log_cas\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Correlation between log_raindays and log_deaths.\n",
    "rain_acc_mthly[[\"log_raindays\", \"log_deaths\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Correlation between log_raindays and log_injured.\n",
    "rain_acc_mthly[[\"log_raindays\", \"log_injured\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#. 4. Which are the top three vehicle types with the highest number of casualties in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of vehicle type columns\n",
    "vehicle_type = [\n",
    "    \"buses\",\n",
    "    \"cyclists_&_pillions\",\n",
    "    \"goods_vans\",\n",
    "    \"lorries\",\n",
    "    \"motor_cars_and_station_wagons\",\n",
    "    \"motor_cyclists_&_pillion_riders\",\n",
    "    \"pedestrians\",\n",
    "    \"pick-ups\",\n",
    "    \"tipper_trucks\",\n",
    "    \"trailers\",\n",
    "    \"others\"\n",
    "]\n",
    "\n",
    "# Create a new DataFrame with the sum of total_cas for each vehicle type\n",
    "vehicle_type_sum = pd.DataFrame(rain_acc_mthly[vehicle_type].sum())\n",
    "\n",
    "# Log-transform the values in the DataFrame\n",
    "vehicle_type = np.log(vehicle_type_sum)\n",
    "\n",
    "# Rename the row to \"total_cas\"\n",
    "vehicle_type.columns = [\"log_cas\"]\n",
    "\n",
    "vehicle_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 15))\n",
    "ax = vehicle_type.plot(kind='barh', legend=False, color='maroon', width=0.5) \n",
    "plt.xlabel(\"Total Casualties(log base-10)\")\n",
    "plt.ylabel('Vehicle Type')\n",
    "plt.title(\"Total Casualties(log base-10) by Vehicle Type\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add labels to each bar\n",
    "for i, (col, value) in enumerate(vehicle_type.iterrows()):\n",
    "    ax.text(float(value['Total Casualties']), i, f'{value[\"Total Casualties\"]:.2f}', va='center')\n",
    "\n",
    "# Remove x-axis label\n",
    "ax.set_xticklabels([])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Top 3 vehicle type with the highest casualties: 1. motor cyclists & pillion riders, 2. motor cars and station wagons, 3. pedestrians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Are there any outliers months in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and a set of subplots\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "\n",
    "# Scatter plot of rain days vs. accident casualties\n",
    "ax.scatter(rain_acc_mthly[\"log_raindays\"], rain_acc_mthly[\"log_cas\"], color='b', alpha=0.3)\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel(\"No. of Rainy Days (log base-10)\")\n",
    "ax.set_ylabel(\"Casualties (log base-10)\")\n",
    "plt.title(\"Scatter Plot: Rainy Days vs. Accident Casualties\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Identify outliers.\n",
    "outlier_indx = np.where(np.abs(stats.zscore(df_rain_acc[\"log_cas\"])) > 3)[0]\n",
    "\n",
    "outlier_indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify data point where index is 49.\n",
    "\n",
    "outlier = df_rain_acc.loc[49]\n",
    "outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new df without the outlier and calculate the correlations again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_outlier = df_rain_acc.drop(index=49)\n",
    "\n",
    "no_outlier.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by month and aggregate values.\n",
    "\n",
    "rain_acc_mthly2 = no_outlier.groupby(\"mth\").agg({\n",
    "    'rain_days': \"sum\", \n",
    "    'log_raindays': \"sum\", \n",
    "    'total_cas': \"sum\",\n",
    "    'total_deaths': \"sum\", \n",
    "    'total_injured': \"sum\", \n",
    "    'log_cas': \"sum\", \n",
    "    'log_deaths': \"sum\", \n",
    "    'log_injured': \"sum\",\n",
    "    'buses': \"sum\", \n",
    "    'cyclists_&_pillions': \"sum\", \n",
    "    'goods_vans': \"sum\", \n",
    "    'lorries': \"sum\",\n",
    "    'motor_cars_and_station_wagons': \"sum\", \n",
    "    'motor_cyclists_&_pillion_riders': \"sum\",\n",
    "    'pedestrians': \"sum\", \n",
    "    'pick-ups': \"sum\", \n",
    "    'tipper_trucks': \"sum\", \n",
    "    'trailers': \"sum\", \n",
    "    'others': \"sum\"\n",
    "}).reset_index()\n",
    "\n",
    "rain_acc_mthly2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_acc_mthly2[[\"log_raindays\", \"log_cas\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_acc_mthly2[[\"log_raindays\", \"log_deaths\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_acc_mthly2[[\"log_raindays\", \"log_injured\"]].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Data\n",
    "\n",
    "There's not a magic bullet recommendation for the right number of plots to understand a given dataset, but visualizing your data is *always* a good idea. Not only does it allow you to quickly convey your findings (even if you have a non-technical audience), it will often reveal trends in your data that escaped you when you were looking only at numbers. It is important to not only create visualizations, but to **interpret your visualizations** as well.\n",
    "\n",
    "**Every plot should**:\n",
    "- Have a title\n",
    "- Have axis labels\n",
    "- Have appropriate tick labels\n",
    "- Text is legible in a plot\n",
    "- Plots demonstrate meaningful and valid relationships\n",
    "- Have an interpretation to aid understanding\n",
    "\n",
    "Here is an example of what your plots should look like following the above guidelines. Note that while the content of this example is unrelated, the principles of visualization hold:\n",
    "\n",
    "![](https://snag.gy/hCBR1U.jpg)\n",
    "*Interpretation: The above image shows that as we increase our spending on advertising, our sales numbers also tend to increase. There is a positive correlation between advertising spending and sales.*\n",
    "\n",
    "---\n",
    "\n",
    "Here are some prompts to get you started with visualizations. Feel free to add additional visualizations as you see fit:\n",
    "1. Use Seaborn's heatmap with pandas `.corr()` to visualize correlations between all numeric features.\n",
    "    - Heatmaps are generally not appropriate for presentations, and should often be excluded from reports as they can be visually overwhelming. **However**, they can be extremely useful in identify relationships of potential interest (as well as identifying potential collinearity before modeling).\n",
    "    - Please take time to format your output, adding a title. Look through some of the additional arguments and options. (Axis labels aren't really necessary, as long as the title is informative).\n",
    "2. Visualize distributions using histograms. If you have a lot, consider writing a custom function and use subplots.\n",
    "    - *OPTIONAL*: Summarize the underlying distributions of your features (in words & statistics)\n",
    "         - Be thorough in your verbal description of these distributions.\n",
    "         - Be sure to back up these summaries with statistics.\n",
    "         - We generally assume that data we sample from a population will be normally distributed. Do we observe this trend? Explain your answers for each distribution and how you think this will affect estimates made from these data.\n",
    "3. Plot and interpret boxplots. \n",
    "    - Boxplots demonstrate central tendency and spread in variables. In a certain sense, these are somewhat redundant with histograms, but you may be better able to identify clear outliers or differences in IQR, etc.\n",
    "    - Multiple values can be plotted to a single boxplot as long as they are of the same relative scale (meaning they have similar min/max values).\n",
    "    - Each boxplot should:\n",
    "        - Only include variables of a similar scale\n",
    "        - Have clear labels for each variable\n",
    "        - Have appropriate titles and labels\n",
    "4. Plot and interpret scatter plots to view relationships between features. Feel free to write a custom function, and subplot if you'd like. Functions save both time and space.\n",
    "    - Your plots should have:\n",
    "        - Two clearly labeled axes\n",
    "        - A proper title\n",
    "        - Colors and symbols that are clear and unmistakable\n",
    "5. Additional plots of your choosing.\n",
    "    - Are there any additional trends or relationships you haven't explored? Was there something interesting you saw that you'd like to dive further into? It's likely that there are a few more plots you might want to generate to support your narrative and recommendations that you are building toward. **As always, make sure you're interpreting your plots as you go**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some ideas for plots that can be generated:\n",
    "\n",
    "- Plot the histogram of the rainfall data with various bins and comment on the distribution of the data - is it centered, skewed?\n",
    "- Plot the box-and-whiskers plot. Comment on the different quartiles and identify any outliers in the dataset. \n",
    "- Is there a correlation between the number of rainy days and total rainfall in the month? What kind of correlation do your suspect? Does the graph show the same?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With no_outliers\n",
    "# Create a double axis chart where the left axis is the no. of rainy days and right is the total casualties (log base-10)\n",
    "fig, ax1 = plt.subplots(figsize = (15, 5))\n",
    "\n",
    "# Plot the rainfall data on the first y-axis (left)\n",
    "color = \"tab:blue\"\n",
    "ax1.set_xlabel(\"date\")\n",
    "ax1.set_ylabel(\"No. of Rain Days (log base-10)\", color=color)\n",
    "ax1.plot(rain_acc_mthly2[\"log_raindays\"], color=color)\n",
    "ax1.tick_params(axis=\"y\", labelcolor=color)\n",
    "\n",
    "# Create a second y-axis (right) for accident data\n",
    "ax2 = ax1.twinx()\n",
    "color = \"tab:red\"\n",
    "ax2.set_ylabel(\"Total Casualties (log base-10)\", color=color)\n",
    "ax2.plot(rain_acc_mthly2[\"log_cas\"], color=color)\n",
    "ax2.tick_params(axis=\"y\", labelcolor=color)\n",
    "\n",
    "new_xticks = range(0, 12)  # Specify the positions of the new ticks\n",
    "new_xtick_labels = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "\n",
    "ax1.set_xticks(new_xticks)  # Set the new tick positions\n",
    "ax1.set_xticklabels(new_xtick_labels)  # Set the new tick labels\n",
    "\n",
    "# Set the x-axis limits to start from 1 and end at 12\n",
    "#ax1.set_xlim(1, 12)\n",
    "\n",
    "# Remove gridlines from both subplots\n",
    "ax1.grid(False)\n",
    "ax2.grid(False)\n",
    "\n",
    "# Add a title and show the plot\n",
    "plt.title(\"No. of Rainy Days vs. Accident Casualties\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With no_outliers\n",
    "# Create a double axis chart where the left axis is the no. of rainy days and right is the total deaths (log base-10)\n",
    "\n",
    "# Create a figure and a set of subplots\n",
    "fig, ax1 = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "# Plot the total_injured data on the first y-axis (left)\n",
    "color = \"tab:blue\"\n",
    "ax1.set_xlabel(\"date\")\n",
    "ax1.set_ylabel(\"No. of Rainy Days (log-10)\", color=color)\n",
    "ax1.plot(rain_acc_mthly2[\"mth\"], rain_acc_mthly2[\"log_raindays\"], color=color)  # Apply log10 to the data column\n",
    "ax1.tick_params(axis=\"y\", labelcolor=color)\n",
    "\n",
    "# Create a second y-axis (right) for total_deaths data\n",
    "ax2 = ax1.twinx()\n",
    "color = \"tab:red\"\n",
    "ax2.set_ylabel(\"Total Deaths (log-10)\", color=color)\n",
    "ax2.plot(rain_acc_mthly2[\"mth\"], rain_acc_mthly2[\"total_deaths\"], color=color)\n",
    "ax2.tick_params(axis=\"y\", labelcolor=color)\n",
    "\n",
    "new_xticks = range(1, 13)  # Specify the positions of the new ticks (1 to 12)\n",
    "new_xtick_labels = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"] \n",
    "\n",
    "ax1.set_xticks(new_xticks)  # Set the new tick positions\n",
    "ax1.set_xticklabels(new_xtick_labels)  # Set the new tick labels\n",
    "\n",
    "# Disable gridlines in the background\n",
    "ax1.xaxis.grid(False)\n",
    "ax1.yaxis.grid(False)\n",
    "ax2.yaxis.grid(False)\n",
    "\n",
    "# Add a title and show the plot\n",
    "plt.title(\"Casualties Trend between 2010-2019\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With no_outliers\n",
    "# Create a double axis chart where the left axis is the no. of rainy days and right is the total injured (log base-10\n",
    "\n",
    "# Create a figure and a set of subplots\n",
    "fig, ax1 = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "# Plot the total_injured data on the first y-axis (left)\n",
    "color = \"tab:blue\"\n",
    "ax1.set_xlabel(\"date\")\n",
    "ax1.set_ylabel(\"No. of Rainy Days (log-10)\", color=color)\n",
    "ax1.plot(rain_acc_mthly2[\"mth\"], rain_acc_mthly2[\"log_raindays\"], color=color)  # Apply log10 to the data column\n",
    "ax1.tick_params(axis=\"y\", labelcolor=color)\n",
    "\n",
    "# Create a second y-axis (right) for total_deaths data\n",
    "ax2 = ax1.twinx()\n",
    "color = \"tab:red\"\n",
    "ax2.set_ylabel(\"Total Injured (log-10)\", color=color)\n",
    "ax2.plot(rain_acc_mthly2[\"mth\"], np.log10(rain_acc_mthly2[\"total_injured\"]), color=color)\n",
    "ax2.tick_params(axis=\"y\", labelcolor=color)\n",
    "\n",
    "new_xticks = range(1, 13)  # Specify the positions of the new ticks (1 to 12)\n",
    "new_xtick_labels = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]  # Labels for the new ticks\n",
    "\n",
    "ax1.set_xticks(new_xticks)  # Set the new tick positions\n",
    "ax1.set_xticklabels(new_xtick_labels)  # Set the new tick labels\n",
    "\n",
    "# Disable gridlines in the background\n",
    "ax1.xaxis.grid(False)\n",
    "ax1.yaxis.grid(False)\n",
    "ax2.yaxis.grid(False)\n",
    "\n",
    "# Add a title and show the plot\n",
    "plt.title(\"Casualties Trend between 2010-2019\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your exploration of the data, what are you key takeaways and recommendations? Make sure to answer your question of interest or address your problem statement here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To-Do:** \n",
    "\n",
    "**Conclusion**:\n",
    "\n",
    "* The correlation between the number of rainy days and total casualties was **0.73** (after removing the outlier, Feb 2014). This implies that rainy days have a **significant impact** on the number of road accident casualties.\n",
    " \n",
    " * The correlation of rainy days vs fatalities, and rainy days vs injured were 0.58 and 0.73 respectively. This shows that rainy days have a **greater effect on injuries but not fatalities**.\n",
    " \n",
    " * Fatalities were less likely affected by **other factors**, such as drink driving, failure to adhere to traffic rules, jaywalking etc (Motorist.sg, 2020).\n",
    " \n",
    " * **Jan, Mar and Apr** (Northeast Monsoon season with the exception of Feb being the dry period) consistently had high number of casualties with relatively high number of rainy days. Though articles on Singapore road accident causes stated only human error reasons (Direct Asia, 2022; Motorist.sg, 2018), **the strong correlation suggests that rainy weather might have elevated those human error and resulted in road accident injuries**.  \n",
    " \n",
    " * The top three vehicle types that had apparently higher number of casualties were **1. motorcyclists and pillion riders, 2. motor cars and station wagons and 3. pedestrians**.\n",
    " \n",
    " * During the **Northeast Monsoon**, the respective **government organizations** should practise more stringent road safety measures tailored to **motorcyclists and pillion riders, motor cars and station wagons and pedestrians**.\n",
    " \n",
    "**Recommendation**:<br>\n",
    "The table below proposes some targeted road safety measures:\n",
    "\n",
    "<img src= \"Images/recommendations.jpg\">\n",
    "\n",
    "**Limitations**:\n",
    "1. **Accuracy of research**\n",
    "As this research uses an aggregated number of rainy days per month, there was no clear indication of which road accidents occurred on a rainy day. For a more accurate analysis, the total number of casualties on rainy days should be used.\n",
    "\n",
    "2. **Limited analysis on other factors**\n",
    "With a focus on analysing the impact of wet weather on road accidents, this research does not take into account other factors that could be the primary reason of road accidents. A seperate research looking into the common human errors should be conducted in order to implement more comprehensive road safety measures.\n",
    "\n",
    "3. **Lack of geolocation data**\n",
    "There is a lack of updated geolocation data that illustrates areas in Singapore that are more susceptible to road accidents. This is another variable worth investigating into to refine those road safety measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to create your README!\n",
    "\n",
    "**To-Do:** *If you combine your problem statement, data dictionary, brief summary of your analysis, and conclusions/recommendations, you have an amazing README.md file that quickly aligns your audience to the contents of your project.* Don't forget to cite your data sources!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
